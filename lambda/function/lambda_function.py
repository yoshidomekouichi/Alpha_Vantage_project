#!/usr/bin/env python3
"""
AWS Lambda Function for Daily Stock Data Fetching

This Lambda function fetches the latest daily stock data from Alpha Vantage API
and stores it in AWS S3. It is designed to be triggered on a schedule.
"""

import os
import sys
import json
import logging
import time
from datetime import datetime, timedelta
import traceback

# „Çø„Ç§„É†„Çæ„Éº„É≥Âá¶ÁêÜÁî®
try:
    # Python 3.9‰ª•Èôç„ÅÆÊ®ôÊ∫ñ„É©„Ç§„Éñ„É©„É™
    from zoneinfo import ZoneInfo
    def get_jst_time():
        return datetime.now(ZoneInfo("Asia/Tokyo"))
except ImportError:
    # Python 3.9Êú™Ê∫Ä„Åæ„Åü„ÅØzoneinfoÈùûÂØæÂøúÁí∞Â¢ÉÁî®
    try:
        import pytz
        def get_jst_time():
            return datetime.now(pytz.timezone('Asia/Tokyo'))
    except ImportError:
        # pytz„ÇÇÂà©Áî®„Åß„Åç„Å™„ÅÑÂ†¥Âêà„ÅØ„ÄÅUTC„Å´9ÊôÇÈñì„ÇíÂä†ÁÆó
        def get_jst_time():
            return datetime.now() + timedelta(hours=9)

# LambdaÁí∞Â¢ÉÂ§âÊï∞„ÇíË®≠ÂÆö
os.environ['AWS_LAMBDA_EXECUTION'] = 'true'

# „É≠„Ç¨„ÉºÂàùÊúüÂåñ
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# src„Éá„Ç£„É¨„ÇØ„Éà„É™„Çí„Ç§„É≥„Éù„Éº„Éà„Éë„Çπ„Å´ËøΩÂä†
sys.path.append('.')
sys.path.append('/var/task')  # LambdaÁí∞Â¢É„Åß„ÅÆ„É´„Éº„Éà„Éá„Ç£„É¨„ÇØ„Éà„É™

# ‰æùÂ≠òÈñ¢‰øÇ„ÅÆ„Ç§„É≥„Éù„Éº„Éà„ÇíÈÅÖÂª∂„Åï„Åõ„ÇãÔºàLambdaÂÆüË°åÊôÇ„Å´ÂøÖË¶Å„Å™„ÇÇ„ÅÆ„Å†„Åë„Çí„Ç§„É≥„Éù„Éº„ÉàÔºâ
try:
    from utils.alerts import AlertManager
except ImportError:
    # LambdaÁí∞Â¢É„Åß„ÅØÁõ¥Êé•„Ç§„É≥„Éù„Éº„Éà„ÇíË©¶„Åø„Çã
    try:
        from alerts import AlertManager
    except ImportError:
        logger.error("AlertManager„ÅÆ„Ç§„É≥„Éù„Éº„Éà„Å´Â§±Êïó„Åó„Åæ„Åó„Åü")

def setup_logging():
    """
    Set up logging configuration.
    
    Returns:
        Logger object
    """
    # „É≠„Ç¨„ÉºÂàùÊúüÂåñ
    logger = logging.getLogger(__name__)
    
    # LambdaÁí∞Â¢É„Åß„ÅØ„É≠„Ç∞„Éá„Ç£„É¨„ÇØ„Éà„É™„Çí/tmp‰ª•‰∏ã„Å´Ë®≠ÂÆö
    log_dir = '/tmp/logs'
    
    # „É≠„Ç∞„Éá„Ç£„É¨„ÇØ„Éà„É™„ÅåÂ≠òÂú®„Åó„Å™„ÅÑÂ†¥Âêà„ÅØ‰ΩúÊàê
    try:
        os.makedirs(log_dir, exist_ok=True)
        logger.info(f"„É≠„Ç∞„Éá„Ç£„É¨„ÇØ„Éà„É™„Çí‰ΩúÊàê„Åó„Åæ„Åó„Åü: {log_dir}")
    except Exception as e:
        logger.error(f"„É≠„Ç∞„Éá„Ç£„É¨„ÇØ„Éà„É™„ÅÆ‰ΩúÊàê„Å´Â§±Êïó„Åó„Åæ„Åó„Åü: {e}")
        logger.error(traceback.format_exc())
    
    # „Éè„É≥„Éâ„É©„Éº„ÇíË®≠ÂÆö
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    
    # „Éï„Ç©„Éº„Éû„ÉÉ„Çø„Éº„ÇíË®≠ÂÆö
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    console_handler.setFormatter(formatter)
    
    # „É≠„Ç¨„Éº„Å´„Éè„É≥„Éâ„É©„Éº„ÇíËøΩÂä†
    logger.addHandler(console_handler)
    
    return logger

def lambda_handler(event, context):
    """
    AWS Lambda handler function.
    
    Args:
        event: Lambda event data
        context: Lambda context
        
    Returns:
        Dictionary with execution results
    """
    start_time = time.time()
    
    # „É≠„ÇÆ„É≥„Ç∞„ÅÆË®≠ÂÆö
    logger = setup_logging()
    
    # Áí∞Â¢ÉÂ§âÊï∞„ÇíÂèñÂæó
    api_key = os.environ.get('ALPHA_VANTAGE_API_KEY', 'demo')
    s3_bucket = os.environ.get('S3_BUCKET', 'Not set')
    region = os.environ.get('REGION', 'ap-northeast-1')
    stock_symbols = os.environ.get('STOCK_SYMBOLS', 'NVDA,AAPL,MSFT')
    mock_mode = os.environ.get('MOCK_MODE', 'false').lower() == 'true'
    debug_mode = os.environ.get('DEBUG_MODE', 'false').lower() == 'true'
    
    # SlackÈÄöÁü•„ÅÆË®≠ÂÆö„ÇíÂèñÂæó
    slack_enabled = os.environ.get('SLACK_ENABLED', 'false').lower() == 'true'
    slack_webhook_url = os.environ.get('SLACK_WEBHOOK_URL', '')
    slack_webhook_url_error = os.environ.get('SLACK_WEBHOOK_URL_ERROR', slack_webhook_url)
    slack_webhook_url_warning = os.environ.get('SLACK_WEBHOOK_URL_WARNING', slack_webhook_url)
    slack_webhook_url_info = os.environ.get('SLACK_WEBHOOK_URL_INFO', slack_webhook_url)
    
    # AlertManager„ÅÆÂàùÊúüÂåñ
    alert_manager = None
    if slack_enabled:
        try:
            alert_manager = AlertManager(
                None,  # email_config
                slack_webhook_url_error,
                slack_webhook_url_warning,
                slack_webhook_url_info
            )
            alert_manager.set_logger(logger)
            logger.info("AlertManager„ÇíÂàùÊúüÂåñ„Åó„Åæ„Åó„Åü")
            
            # „Éá„Éê„ÉÉ„Ç∞„É¢„Éº„Éâ„ÅÆÂ†¥Âêà„ÅØSlackË®≠ÂÆö„ÅÆË©≥Á¥∞„Çí„É≠„Ç∞„Å´Âá∫Âäõ
            if debug_mode:
                logger.debug("=" * 80)
                logger.debug("SlackË®≠ÂÆö„ÅÆË©≥Á¥∞:")
                logger.debug(f"slack_enabled: {slack_enabled}")
                logger.debug(f"slack_webhook_url: {slack_webhook_url}")
                logger.debug(f"slack_webhook_url_error: {slack_webhook_url_error}")
                logger.debug(f"slack_webhook_url_warning: {slack_webhook_url_warning}")
                logger.debug(f"slack_webhook_url_info: {slack_webhook_url_info}")
                logger.debug("=" * 80)
        except Exception as e:
            logger.error(f"AlertManager„ÅÆÂàùÊúüÂåñ„Å´Â§±Êïó„Åó„Åæ„Åó„Åü: {e}")
            logger.error(traceback.format_exc())
    
    # ÂÆüË°å„É¢„Éº„Éâ„ÇíË®≠ÂÆö
    env_type = "Lambda"
    if mock_mode:
        env_type += " (Mock)"
    
    # ÂÆüË°åÈñãÂßã„É≠„Ç∞
    logger.info("=" * 80)
    logger.info(f"üöÄ Starting Lambda function for daily stock data fetch at {datetime.now().isoformat()}")
    logger.info(f"üîß Environment: {env_type}")
    logger.info(f"üîë API Key: {'*' * (len(api_key) - 4) + api_key[-4:] if len(api_key) > 4 else '****'}")
    logger.info(f"ü™£ S3 Bucket: {s3_bucket}")
    logger.info(f"üåê Region: {region}")
    logger.info(f"üìä Stock Symbols: {stock_symbols}")
    logger.info(f"üêõ Debug Mode: {debug_mode}")
    logger.info("=" * 80)
    
    try:
        # „É¢„ÉÉ„ÇØ„É¢„Éº„Éâ„ÅÆÂ†¥Âêà„ÅØ„ÉÄ„Éü„Éº„Éá„Éº„Çø„ÇíËøî„Åô
        if mock_mode:
            logger.info("„É¢„ÉÉ„ÇØ„É¢„Éº„Éâ„ÅßÂÆüË°å‰∏≠„Åß„Åô„ÄÇ„ÉÄ„Éü„Éº„Éá„Éº„Çø„ÇíËøî„Åó„Åæ„Åô„ÄÇ")
            
            # ÂÆüË°åÊôÇÈñì„ÇíË®àÁÆó
            end_time = time.time()
            execution_time = end_time - start_time
            
            return {
                'statusCode': 200,
                'body': json.dumps({
                    'success': True,
                    'execution_time': f"{execution_time:.2f} seconds",
                    'message': 'Mock mode execution successful',
                    'data': {
                        'symbols': stock_symbols.split(','),
                        'timestamp': datetime.now().isoformat()
                    }
                })
            }
        
        # ÂÆüÈöõ„ÅÆ„Éá„Éº„ÇøÂèñÂæóÂá¶ÁêÜ
        logger.info("Alpha Vantage API„Åã„Çâ„Éá„Éº„Çø„ÇíÂèñÂæó„Åó„Åæ„Åô...")
        
        # „Åì„Åì„ÅßÂÆüÈöõ„ÅÆ„Éá„Éº„ÇøÂèñÂæóÂá¶ÁêÜ„ÇíË°å„ÅÜ
        # Ê≥®ÊÑè: ‰æùÂ≠òÈñ¢‰øÇ„ÅÆ„Ç§„É≥„Éù„Éº„Éà„ÅØ„Åì„Åì„ÅßË°å„ÅÜ
        try:
            import boto3
            from botocore.exceptions import ClientError
            
            # S3„ÇØ„É©„Ç§„Ç¢„É≥„Éà„ÇíÂàùÊúüÂåñ
            s3_client = boto3.client('s3', region_name=region)
            
            # Ê†™Âºè„Ç∑„É≥„Éú„É´„ÅÆ„É™„Çπ„Éà
            symbols = stock_symbols.split(',')
            
            # ÂêÑ„Ç∑„É≥„Éú„É´„Å´ÂØæ„Åó„Å¶Âá¶ÁêÜ„ÇíÂÆüË°å
            results = {}
            error_details = {}  # „Ç®„É©„Éº„ÅÆË©≥Á¥∞„ÇíË®òÈå≤„Åô„ÇãËæûÊõ∏
            data_sizes = {}     # ÂêÑ„Ç∑„É≥„Éú„É´„ÅÆ„Éá„Éº„Çø„Çµ„Ç§„Ç∫„ÇíË®òÈå≤„Åô„ÇãËæûÊõ∏
            s3_paths = {}       # ÂêÑ„Ç∑„É≥„Éú„É´„ÅÆS3„Éë„Çπ„ÇíË®òÈå≤„Åô„ÇãËæûÊõ∏
            symbol_dates = {}   # ÂêÑ„Ç∑„É≥„Éú„É´„ÅÆÊó•‰ªò„ÇíË®òÈå≤„Åô„ÇãËæûÊõ∏
            latest_date = None  # ÊúÄÊñ∞„ÅÆÊó•‰ªòÔºà„Åô„Åπ„Å¶„ÅÆ„Ç∑„É≥„Éú„É´„ÅßÂÖ±ÈÄöÔºâ
            for symbol in symbols:
                logger.info(f"„Ç∑„É≥„Éú„É´ {symbol} „ÅÆÂá¶ÁêÜ„ÇíÈñãÂßã„Åó„Åæ„Åô...")
                
                # Alpha Vantage API„Åã„Çâ„Éá„Éº„Çø„ÇíÂèñÂæó
                try:
                    import requests
                    
                    # API„É™„ÇØ„Ç®„Çπ„ÉàURL„ÇíÊßãÁØâ
                    base_url = "https://www.alphavantage.co/query"
                    params = {
                        "function": "TIME_SERIES_DAILY",
                        "symbol": symbol,
                        "apikey": api_key,
                        "outputsize": "compact"  # ÊúÄÊñ∞„ÅÆ100‰ª∂„ÅÆ„Éá„Éº„Çø„ÇíÂèñÂæó
                    }
                    
                    # API„É™„ÇØ„Ç®„Çπ„Éà„ÇíÈÄÅ‰ø°
                    logger.info(f"Alpha Vantage API„Å´„É™„ÇØ„Ç®„Çπ„Éà„ÇíÈÄÅ‰ø°„Åó„Åæ„Åô: {base_url}?function={params['function']}&symbol={params['symbol']}&outputsize={params['outputsize']}")
                    response = requests.get(base_url, params=params)
                    
                    # „É¨„Çπ„Éù„É≥„Çπ„ÇíÁ¢∫Ë™ç
                    if response.status_code != 200:
                        error_msg = f"API„É™„ÇØ„Ç®„Çπ„Éà„ÅåÂ§±Êïó„Åó„Åæ„Åó„Åü: „Çπ„ÉÜ„Éº„Çø„Çπ„Ç≥„Éº„Éâ {response.status_code}"
                        logger.error(error_msg)
                        logger.error(f"„É¨„Çπ„Éù„É≥„Çπ: {response.text}")
                        results[symbol] = 'error'
                        error_details[symbol] = {
                            'error_type': 'API Request Error',
                            'status_code': response.status_code,
                            'message': error_msg,
                            'response': response.text[:200] + '...' if len(response.text) > 200 else response.text
                        }
                        continue
                    
                    # JSON„Éá„Éº„Çø„ÇíËß£Êûê
                    data = response.json()
                    
                    # „Ç®„É©„Éº„ÉÅ„Çß„ÉÉ„ÇØ
                    if "Error Message" in data:
                        error_msg = f"API„Ç®„É©„Éº: {data['Error Message']}"
                        logger.error(error_msg)
                        results[symbol] = 'error'
                        error_details[symbol] = {
                            'error_type': 'API Error',
                            'message': error_msg,
                            'api_error': data['Error Message']
                        }
                        continue
                    
                    if "Time Series (Daily)" not in data:
                        error_msg = f"‰∫àÊúü„Åó„Å™„ÅÑAPI„É¨„Çπ„Éù„É≥„ÇπÂΩ¢Âºè"
                        logger.error(f"{error_msg}: {data}")
                        results[symbol] = 'error'
                        error_details[symbol] = {
                            'error_type': 'Unexpected Response Format',
                            'message': error_msg,
                            'response_keys': list(data.keys())
                        }
                        continue
                    
                    # ÊúÄÊñ∞„ÅÆÊó•‰ªò„ÅÆ„Éá„Éº„Çø„ÇíÂèñÂæó
                    time_series = data["Time Series (Daily)"]
                    latest_date = list(time_series.keys())[0]  # ÊúÄÂàù„ÅÆ„Ç≠„Éº„ÅåÊúÄÊñ∞„ÅÆÊó•‰ªò
                    latest_data = time_series[latest_date]
                    
                    # ÂøÖË¶Å„Å™„Éá„Éº„Çø„ÇíÊäΩÂá∫
                    stock_data = {
                        'symbol': symbol,
                        'timestamp': datetime.now().isoformat(),
                        'date': latest_date,
                        'open': float(latest_data['1. open']),
                        'high': float(latest_data['2. high']),
                        'low': float(latest_data['3. low']),
                        'close': float(latest_data['4. close']),
                        'volume': int(latest_data['5. volume'])
                    }
                    
                    logger.info(f"„Éá„Éº„Çø„ÇíÂèñÂæó„Åó„Åæ„Åó„Åü: {symbol} ({latest_date})")
                    
                except Exception as e:
                    error_msg = f"„Éá„Éº„ÇøÂèñÂæó‰∏≠„Å´„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü: {e}"
                    logger.error(error_msg)
                    logger.error(traceback.format_exc())
                    results[symbol] = 'error'
                    error_details[symbol] = {
                        'error_type': 'Data Fetch Error',
                        'message': error_msg,
                        'symbol': symbol,
                        'error': str(e)
                    }
                    continue
                
                # „Éá„Éº„Çø„Çµ„Ç§„Ç∫„ÇíË®àÁÆó
                json_data = json.dumps(stock_data)
                data_size = len(json_data)
                data_sizes[symbol] = data_size
                
                # ÂâçÂõû„ÅÆ„Éá„Éº„Çø„ÇíÂèñÂæó„Åó„Å¶ÊØîËºÉ„Åô„Çã„Åü„ÇÅ„ÅÆÊ∫ñÂÇô
                previous_data = None
                previous_size = 0
                size_diff_percent = 0
                
                try:
                    # ÂâçÂõû„ÅÆ„Éá„Éº„Çø„ÇíS3„Åã„ÇâË™≠„ÅøËæº„ÇÄË©¶„Åø
                    try:
                        # utils/s3_paths.py„Çí„Ç§„É≥„Éù„Éº„Éà
                        try:
                            from utils.s3_paths import get_s3_key
                        except ImportError:
                            # LambdaÁí∞Â¢É„Åß„ÅØÁõ¥Êé•„Ç§„É≥„Éù„Éº„Éà„ÇíË©¶„Åø„Çã
                            from s3_paths import get_s3_key
                        
                        # Áí∞Â¢ÉË®≠ÂÆö„ÇíÂèñÂæó
                        is_mock = os.environ.get('MOCK_MODE', 'false').lower() == 'true'
                        
                        # ÊúÄÊñ∞„Éá„Éº„Çø„ÅÆS3„Ç≠„Éº„ÇíÁîüÊàê
                        latest_key = get_s3_key(
                            symbol=symbol,
                            data_type='raw',
                            is_latest=True,
                            is_mock=is_mock
                        )
                    except ImportError:
                        # s3_paths.py„ÅåË¶ã„Å§„Åã„Çâ„Å™„ÅÑÂ†¥Âêà„ÅØÊóßÂΩ¢Âºè„Çí‰ΩøÁî®
                        latest_key = f"{symbol}/latest.json"
                    
                    # ÂâçÂõû„ÅÆ„Éá„Éº„Çø„ÇíÂèñÂæó
                    try:
                        response = s3_client.get_object(Bucket=s3_bucket, Key=latest_key)
                        previous_data = json.loads(response['Body'].read().decode('utf-8'))
                        previous_size = len(json.dumps(previous_data))
                        
                        # „Çµ„Ç§„Ç∫„ÅÆÂ∑ÆÂàÜ„ÇíË®àÁÆóÔºà„Éë„Éº„Çª„É≥„ÉàÔºâ
                        if previous_size > 0:
                            size_diff_percent = ((data_size - previous_size) / previous_size) * 100
                        
                        logger.info(f"ÂâçÂõû„ÅÆ„Éá„Éº„Çø„Å®ÊØîËºÉ: ÁèæÂú®={data_size}„Éê„Ç§„Éà, ÂâçÂõû={previous_size}„Éê„Ç§„Éà, Â∑ÆÂàÜ={size_diff_percent:.2f}%")
                    except Exception as e:
                        logger.warning(f"ÂâçÂõû„ÅÆ„Éá„Éº„Çø„ÅÆÂèñÂæó„Å´Â§±Êïó„Åó„Åæ„Åó„ÅüÔºàÂàùÂõûÂÆüË°å„ÅÆÂèØËÉΩÊÄß„ÅÇ„ÇäÔºâ: {e}")
                except Exception as e:
                    logger.warning(f"„Éá„Éº„Çø„Çµ„Ç§„Ç∫ÊØîËºÉÂá¶ÁêÜ‰∏≠„Å´„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü: {e}")
                
                # ÂêÑ„Ç∑„É≥„Éú„É´„ÅÆÊó•‰ªò„Çí‰øùÂ≠ò
                symbol_date = stock_data['date']
                symbol_dates[symbol] = symbol_date
                
                # S3„Å´„Éá„Éº„Çø„Çí‰øùÂ≠ò
                try:
                    # Êñ∞„Åó„ÅÑS3„Éë„ÇπÊßãÈÄ†„Çí‰ΩøÁî®
                    try:
                        # utils/s3_paths.py„Çí„Ç§„É≥„Éù„Éº„Éà
                        try:
                            from utils.s3_paths import get_s3_key, get_metadata_key
                        except ImportError:
                            # LambdaÁí∞Â¢É„Åß„ÅØÁõ¥Êé•„Ç§„É≥„Éù„Éº„Éà„ÇíË©¶„Åø„Çã
                            from s3_paths import get_s3_key, get_metadata_key
                        
                        # Áí∞Â¢ÉË®≠ÂÆö„ÇíÂèñÂæó
                        is_mock = os.environ.get('MOCK_MODE', 'false').lower() == 'true'
                        
                        # Ê®ôÊ∫ñÈöéÂ±§ÊßãÈÄ†(V2)„ÅÆS3„Ç≠„Éº„ÇíÁîüÊàê
                        # 1. Êó•Ê¨°„Éá„Éº„ÇøÁî®„ÅÆ„Ç≠„Éº
                        # ÂêÑ„Ç∑„É≥„Éú„É´„Åî„Å®„Å´API„Åã„ÇâÂèñÂæó„Åó„ÅüÊó•‰ªò„Çí‰ΩøÁî®
                        symbol_date = stock_data['date']  # API„Åã„ÇâÂèñÂæó„Åó„ÅüÊó•‰ªò
                        daily_key = get_s3_key(
                            symbol=symbol,
                            data_type='raw',
                            date=symbol_date,  # API„Åã„ÇâÂèñÂæó„Åó„ÅüÊó•‰ªò„Çí‰ΩøÁî®
                            is_latest=False,
                            is_mock=is_mock
                        )
                        
                        # 2. ÊúÄÊñ∞„Éá„Éº„ÇøÁî®„ÅÆ„Ç≠„Éº
                        latest_key = get_s3_key(
                            symbol=symbol,
                            data_type='raw',
                            is_latest=True,
                            is_mock=is_mock
                        )
                        
                        # 3. ÂÖ®ÊúüÈñì„Éá„Éº„ÇøÁî®„ÅÆ„Ç≠„ÉºÔºà‰ªäÂõû„ÅØÊúÄÊñ∞„Éá„Éº„Çø„Å®Âêå„ÅòÔºâ
                        full_key = get_s3_key(
                            symbol=symbol,
                            data_type='raw',
                            is_mock=is_mock
                        )
                        
                        # 4. „É°„Çø„Éá„Éº„ÇøÁî®„ÅÆ„Ç≠„Éº
                        metadata_key = get_metadata_key(
                            symbol=symbol,
                            data_type='raw',
                            is_mock=is_mock
                        )
                    except ImportError:
                        # s3_paths.py„ÅåË¶ã„Å§„Åã„Çâ„Å™„ÅÑÂ†¥Âêà„ÅØÊóßÂΩ¢Âºè„Çí‰ΩøÁî®
                        logger.warning("s3_paths.py„ÅåË¶ã„Å§„Åã„Çâ„Å™„ÅÑ„Åü„ÇÅ„ÄÅÊóßÂΩ¢Âºè„ÅÆS3„Éë„Çπ„Çí‰ΩøÁî®„Åó„Åæ„Åô")
                        daily_key = f"daily/{symbol}/{symbol_date}.json"  # API„Åã„ÇâÂèñÂæó„Åó„ÅüÊó•‰ªò„Çí‰ΩøÁî®
                        latest_key = f"{symbol}/latest.json"
                        full_key = f"{symbol}/full.json"
                        metadata_key = f"{symbol}/metadata.json"
                    
                    # „É°„Ç§„É≥„ÅÆS3„Éë„Çπ„ÇíË®≠ÂÆöÔºàÊó•Ê¨°„Éá„Éº„ÇøÔºâ
                    s3_path = f"s3://{s3_bucket}/{daily_key}"
                    s3_paths[symbol] = s3_path
                    
                    # „É°„Çø„Éá„Éº„Çø„ÅÆ‰ΩúÊàê
                    metadata = {
                        'symbol': symbol,
                        'last_updated': datetime.now().isoformat(),
                        'latest_date': symbol_date,  # ÂêÑ„Ç∑„É≥„Éú„É´„ÅÆÊó•‰ªò„Çí‰ΩøÁî®
                        'data_points': 1,  # Êó•Ê¨°„Éá„Éº„Çø„ÅÆ„Åø„ÅÆÂ†¥Âêà
                        'date_range': {
                            'start': symbol_date,  # ÂêÑ„Ç∑„É≥„Éú„É´„ÅÆÊó•‰ªò„Çí‰ΩøÁî®
                            'end': symbol_date     # ÂêÑ„Ç∑„É≥„Éú„É´„ÅÆÊó•‰ªò„Çí‰ΩøÁî®
                        }
                    }
                    
                    # 1. Êó•Ê¨°„Éá„Éº„Çø„ÅÆ‰øùÂ≠ò
                    s3_client.put_object(
                        Bucket=s3_bucket,
                        Key=daily_key,
                        Body=json_data,
                        ContentType='application/json'
                    )
                    logger.info(f"Êó•Ê¨°„Éá„Éº„Çø„ÇíS3„Å´‰øùÂ≠ò„Åó„Åæ„Åó„Åü: s3://{s3_bucket}/{daily_key}")
                    
                    # 2. ÊúÄÊñ∞„Éá„Éº„Çø„ÅÆ‰øùÂ≠ò
                    s3_client.put_object(
                        Bucket=s3_bucket,
                        Key=latest_key,
                        Body=json_data,
                        ContentType='application/json'
                    )
                    logger.info(f"ÊúÄÊñ∞„Éá„Éº„Çø„ÇíS3„Å´‰øùÂ≠ò„Åó„Åæ„Åó„Åü: s3://{s3_bucket}/{latest_key}")
                    
                    # 3. ÂÖ®ÊúüÈñì„Éá„Éº„Çø„ÅÆ‰øùÂ≠òÔºà‰ªäÂõû„ÅØÊúÄÊñ∞„Éá„Éº„Çø„Å®Âêå„ÅòÔºâ
                    s3_client.put_object(
                        Bucket=s3_bucket,
                        Key=full_key,
                        Body=json_data,
                        ContentType='application/json'
                    )
                    logger.info(f"ÂÖ®ÊúüÈñì„Éá„Éº„Çø„ÇíS3„Å´‰øùÂ≠ò„Åó„Åæ„Åó„Åü: s3://{s3_bucket}/{full_key}")
                    
                    # 4. „É°„Çø„Éá„Éº„Çø„ÅÆ‰øùÂ≠ò
                    s3_client.put_object(
                        Bucket=s3_bucket,
                        Key=metadata_key,
                        Body=json.dumps(metadata),
                        ContentType='application/json'
                    )
                    logger.info(f"„É°„Çø„Éá„Éº„Çø„ÇíS3„Å´‰øùÂ≠ò„Åó„Åæ„Åó„Åü: s3://{s3_bucket}/{metadata_key}")
                    
                    results[symbol] = 'success'
                except ClientError as e:
                    error_msg = f"S3„Å∏„ÅÆ„Éá„Éº„Çø‰øùÂ≠ò„Å´Â§±Êïó„Åó„Åæ„Åó„Åü: {e}"
                    logger.error(error_msg)
                    results[symbol] = 'error'
                    error_details[symbol] = {
                        'error_type': 'S3 Storage Error',
                        'message': error_msg,
                        's3_bucket': s3_bucket,
                        's3_key': s3_key,
                        'error': str(e)
                    }
                except Exception as e:
                    error_msg = f"S3„Å∏„ÅÆ„Éá„Éº„Çø‰øùÂ≠ò‰∏≠„Å´‰∫àÊúü„Åó„Å™„ÅÑ„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü: {e}"
                    logger.error(error_msg)
                    logger.error(traceback.format_exc())
                    results[symbol] = 'error'
                    error_details[symbol] = {
                        'error_type': 'Unexpected S3 Error',
                        'message': error_msg,
                        'error': str(e)
                    }
            
            # ÂÆüË°åÊôÇÈñì„ÇíË®àÁÆó
            end_time = time.time()
            execution_time = end_time - start_time
            
            # ÁµêÊûú„ÇíÈõÜË®à
            success_count = sum(1 for result in results.values() if result == 'success')
            failure_count = sum(1 for result in results.values() if result != 'success')
            
            # SlackÈÄöÁü•„ÇíÈÄÅ‰ø°
            if slack_enabled and alert_manager:
                try:
                    # ÂÆüË°åÁí∞Â¢ÉÊÉÖÂ†±„ÇíÂèñÂæó
                    env_info = f"Environment: {env_type}"
                    utc_timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    jst_timestamp = get_jst_time().strftime("%Y-%m-%d %H:%M:%S")
                    
                    # ÂÖ±ÈÄö„ÅÆ„Éï„Ç£„Éº„É´„Éâ
                    common_fields = [
                        {"title": "Environment", "value": env_type, "short": True},
                        {"title": "Execution Time", "value": f"{execution_time:.2f} seconds", "short": True},
                        {"title": "Timestamp (UTC)", "value": utc_timestamp, "short": True},
                        {"title": "Timestamp (JST)", "value": jst_timestamp, "short": True},
                    ]
                    
                    # ÁµêÊûú„Å´Âü∫„Å•„ÅÑ„Å¶ÈÄöÁü•„ÇíÈÄÅ‰ø°
                    if failure_count > 0:
                        # Â§±Êïó„Åó„Åü„Ç∑„É≥„Éú„É´„ÇíÊäΩÂá∫
                        failed_symbols = [symbol for symbol, result in results.items() if result != 'success']
                        
                        # Â§±ÊïóÊÉÖÂ†±„ÇíË©≥Á¥∞„Å´Âê´„ÇÅ„Çã
                        failure_fields = [
                            {"title": "Failed Symbols", "value": ", ".join(failed_symbols), "short": False},
                            {"title": "Success Count", "value": str(success_count), "short": True},
                            {"title": "Failure Count", "value": str(failure_count), "short": True}
                        ]
                        
                        # „Ç®„É©„Éº„ÅÆË©≥Á¥∞ÊÉÖÂ†±„ÇíËøΩÂä†
                        for symbol in failed_symbols:
                            if symbol in error_details:
                                error_info = error_details[symbol]
                                failure_fields.append({
                                    "title": f"Error Details for {symbol}",
                                    "value": f"Type: {error_info.get('error_type', 'Unknown')}\nMessage: {error_info.get('message', 'No message')}",
                                    "short": False
                                })
                        
                        # Ë©≥Á¥∞„Å™ÁµêÊûúÊÉÖÂ†±
                        detailed_results = "\n".join([f"{symbol}: {result}" for symbol, result in results.items()])
                        
                        # Ë≠¶Âëä„Ç¢„É©„Éº„Éà„ÇíÈÄÅ‰ø°
                        alert_message = f"‚ö†Ô∏è Lambda: Daily stock data fetch completed with {failure_count} failures"
                        alert_details = f"""
WARNING: Some stock data fetch operations failed.

Execution time: {execution_time:.2f} seconds
Environment: {env_type}
Successful: {success_count}
Failed: {failure_count}

Failed symbols: {', '.join(failed_symbols)}

Detailed results:
{detailed_results}
"""
                        alert_manager.send_warning_alert(
                            alert_message,
                            alert_details,
                            source="lambda_function.py",
                            send_email=False,
                            send_slack=True,
                            additional_fields=common_fields + failure_fields
                        )
                        logger.info("‚úÖ Ë≠¶ÂëäÈÄöÁü•„ÇíÈÄÅ‰ø°„Åó„Åæ„Åó„Åü")
                    else:
                        # ÊàêÂäü„Åó„Åü„Ç∑„É≥„Éú„É´„ÇíÊäΩÂá∫
                        successful_symbols = [symbol for symbol, result in results.items() if result == 'success']
                        
                        # „Éá„Éº„ÇøÊó•‰ªò„ÅÆÊÉÖÂ†±
                        # ÂêÑ„Ç∑„É≥„Éú„É´„ÅÆÊó•‰ªò„ÇíË°®Á§∫
                        date_info = ", ".join([f"{symbol}: {date}" for symbol, date in symbol_dates.items()])
                        data_date_field = {"title": "Data Dates", "value": date_info, "short": False}
                        
                        # „Éá„Éº„ÇøÊÉÖÂ†±„Éï„Ç£„Éº„É´„Éâ„Çí‰ΩúÊàê
                        total_data_size = sum(data_sizes.values())
                        avg_data_size = total_data_size / len(data_sizes) if data_sizes else 0
                        total_files = success_count * 4  # ÂêÑ„Ç∑„É≥„Éú„É´„Å´„Å§„Åç4Á®ÆÈ°û„ÅÆ„Éï„Ç°„Ç§„É´
                        
                        # ÂêÑ„Éï„Ç°„Ç§„É´„Çø„Ç§„Éó„ÅÆ„Çµ„Ç§„Ç∫„ÇíË®àÁÆóÔºà‰ªäÂõû„ÅØÂÖ®„Å¶Âêå„ÅòÔºâ
                        daily_size = total_data_size
                        latest_size = total_data_size
                        full_size = total_data_size
                        metadata_size = len(json.dumps(metadata)) * success_count if success_count > 0 else 0
                        
                        # ÂâçÂõû„Å®„ÅÆÊØîËºÉÊÉÖÂ†±„ÇíÂèñÂæó
                        size_diff_info = ""
                        for symbol, size in data_sizes.items():
                            try:
                                # ÂâçÂõû„ÅÆ„Éá„Éº„Çø„ÇíS3„Åã„ÇâË™≠„ÅøËæº„ÇÄË©¶„Åø
                                try:
                                    # utils/s3_paths.py„Çí„Ç§„É≥„Éù„Éº„Éà
                                    try:
                                        from utils.s3_paths import get_s3_key
                                    except ImportError:
                                        # LambdaÁí∞Â¢É„Åß„ÅØÁõ¥Êé•„Ç§„É≥„Éù„Éº„Éà„ÇíË©¶„Åø„Çã
                                        from s3_paths import get_s3_key
                                    
                                    # Áí∞Â¢ÉË®≠ÂÆö„ÇíÂèñÂæó
                                    is_mock = os.environ.get('MOCK_MODE', 'false').lower() == 'true'
                                    
                                    # ÊúÄÊñ∞„Éá„Éº„Çø„ÅÆS3„Ç≠„Éº„ÇíÁîüÊàê
                                    latest_key = get_s3_key(
                                        symbol=symbol,
                                        data_type='raw',
                                        is_latest=True,
                                        is_mock=is_mock
                                    )
                                except ImportError:
                                    # s3_paths.py„ÅåË¶ã„Å§„Åã„Çâ„Å™„ÅÑÂ†¥Âêà„ÅØÊóßÂΩ¢Âºè„Çí‰ΩøÁî®
                                    latest_key = f"{symbol}/latest.json"
                                
                                # ÂâçÂõû„ÅÆ„Éá„Éº„Çø„ÇíÂèñÂæó
                                response = s3_client.get_object(Bucket=s3_bucket, Key=latest_key)
                                previous_data = json.loads(response['Body'].read().decode('utf-8'))
                                previous_size = len(json.dumps(previous_data))
                                
                                # „Çµ„Ç§„Ç∫„ÅÆÂ∑ÆÂàÜ„ÇíË®àÁÆóÔºà„Éë„Éº„Çª„É≥„ÉàÔºâ
                                if previous_size > 0:
                                    size_diff_percent = ((size - previous_size) / previous_size) * 100
                                    size_diff_info += f"- {symbol}: {size_diff_percent:+.2f}% ({previous_size} ‚Üí {size} „Éê„Ç§„Éà)\n"
                            except Exception as e:
                                size_diff_info += f"- {symbol}: ÂâçÂõû„Éá„Éº„Çø„Å™„ÅóÔºàÂàùÂõûÂÆüË°åÔºâ\n"
                        
                        # „Éá„Éº„ÇøÊÉÖÂ†±„Éï„Ç£„Éº„É´„Éâ„Çí‰ΩúÊàê
                        data_info_field = {
                            "title": "Data Information", 
                            "value": f"- Âá¶ÁêÜ„Åó„Åü„Ç∑„É≥„Éú„É´Êï∞: {success_count}\n"
                                    f"- Êõ¥Êñ∞„Åó„Åü„Éï„Ç°„Ç§„É´Êï∞: {success_count}√ó4 = {total_files} „Éï„Ç°„Ç§„É´\n"
                                    f"- „Éá„Éº„Çø„Çµ„Ç§„Ç∫: ÂêàË®à {total_data_size / 1024:.2f} KB (Âπ≥Âùá {avg_data_size / 1024:.2f} KB/„Ç∑„É≥„Éú„É´)\n"
                                    f"- „Éï„Ç°„Ç§„É´Âà•„Çµ„Ç§„Ç∫:\n"
                                    f"  ‚Ä¢ Êó•Ê¨°„Éá„Éº„Çø: {daily_size / 1024:.2f} KB\n"
                                    f"  ‚Ä¢ ÊúÄÊñ∞„Éá„Éº„Çø: {latest_size / 1024:.2f} KB\n"
                                    f"  ‚Ä¢ ÂÖ®ÊúüÈñì„Éá„Éº„Çø: {full_size / 1024:.2f} KB\n"
                                    f"  ‚Ä¢ „É°„Çø„Éá„Éº„Çø: {metadata_size / 1024:.2f} KB",
                            "short": False
                        }
                        
                        # ÂâçÂõû„Å®„ÅÆÊØîËºÉÊÉÖÂ†±„Éï„Ç£„Éº„É´„Éâ„Çí‰ΩúÊàê
                        data_change_field = {
                            "title": "Data Change Information",
                            "value": size_diff_info if size_diff_info else "- ÂâçÂõû„Éá„Éº„Çø„Å™„ÅóÔºàÂàùÂõûÂÆüË°åÔºâ",
                            "short": False
                        }
                        
                        # S3„Éë„ÇπÊÉÖÂ†±„ÇíËøΩÂä†Ôºà‰ª£Ë°®ÁöÑ„Å™„Éë„Çπ„Å®ÊÆã„Çä„ÅÆ‰ª∂Êï∞Ôºâ
                        s3_path_examples = []
                        if successful_symbols:
                            # ÊúÄÂàù„ÅÆ3„Å§„ÅÆ„Ç∑„É≥„Éú„É´Ôºà„Åæ„Åü„ÅØÂÖ®ÈÉ®Ôºâ„ÅÆ„Éë„Çπ„ÇíË°®Á§∫
                            display_count = min(3, len(successful_symbols))
                            for i in range(display_count):
                                symbol = successful_symbols[i]
                                # Êó•Ê¨°„Éá„Éº„Çø„ÅÆ„Éë„Çπ„ÇíË°®Á§∫
                                s3_path_examples.append(f"{symbol}: {s3_paths[symbol]}")
                            
                            # ÊÆã„Çä„ÅÆ‰ª∂Êï∞„Åå„ÅÇ„ÇãÂ†¥Âêà„ÅØË°®Á§∫
                            remaining = len(successful_symbols) - display_count
                            if remaining > 0:
                                s3_path_examples.append(f"... ‰ªñ {remaining} ‰ª∂")
                        
                        # „Éï„Ç°„Ç§„É´„Çø„Ç§„Éó„ÅÆ„Çµ„Éû„É™„ÉºÊÉÖÂ†±„ÇíËøΩÂä†
                        file_types_summary = "ÂêÑ„Ç∑„É≥„Éú„É´„Å´„Å§„Åç‰ª•‰∏ã„ÅÆ4Á®ÆÈ°û„ÅÆ„Éï„Ç°„Ç§„É´„ÇíÊõ¥Êñ∞„Åó„Åæ„Åó„ÅüÔºö\n"
                        file_types_summary += "- Êó•Ê¨°„Éá„Éº„Çø: .../daily/{year}/{month}/{day}.json\n"
                        file_types_summary += "- ÊúÄÊñ∞„Éá„Éº„Çø: .../latest.json\n"
                        file_types_summary += "- ÂÖ®ÊúüÈñì„Éá„Éº„Çø: .../full.json\n"
                        file_types_summary += "- „É°„Çø„Éá„Éº„Çø: .../metadata.json"
                        
                        s3_paths_field = {
                            "title": "S3 Storage Paths", 
                            "value": file_types_summary + "\n\n" + "\n".join(s3_path_examples), 
                            "short": False
                        }
                        
                        # ÊàêÂäüÊÉÖÂ†±„ÇíË©≥Á¥∞„Å´Âê´„ÇÅ„Çã
                        success_fields = [
                            {"title": "Successful Symbols", "value": ", ".join(successful_symbols), "short": False},
                            {"title": "Total Successful", "value": str(success_count), "short": True},
                            data_date_field,
                            data_info_field,
                            data_change_field,
                            s3_paths_field
                        ]
                        
                        # ÊàêÂäü„Ç¢„É©„Éº„Éà„ÇíÈÄÅ‰ø°
                        alert_message = f"‚úÖ Lambda: Daily stock data fetch completed successfully for all {success_count} symbols"
                        
                        # ÂêÑ„Ç∑„É≥„Éú„É´„ÅÆÊó•‰ªòÊÉÖÂ†±„ÇíË©≥Á¥∞„Å´Âê´„ÇÅ„Çã
                        date_details = "\n".join([f"- {symbol}: {date}" for symbol, date in symbol_dates.items()])
                        
                        alert_details = f"""
INFO: Stock data fetch summary.

Execution time: {execution_time:.2f} seconds
Environment: {env_type}
Successful symbols: {', '.join(successful_symbols)}
Total successful: {success_count}
Total data size: {total_data_size / 1024:.2f} KB

Data dates:
{date_details}
"""
                        alert_manager.send_success_alert(
                            alert_message,
                            alert_details,
                            source="lambda_function.py",
                            send_email=False,
                            send_slack=True,
                            additional_fields=common_fields + success_fields
                        )
                        logger.info("‚úÖ ÊàêÂäüÈÄöÁü•„ÇíÈÄÅ‰ø°„Åó„Åæ„Åó„Åü")
                except Exception as e:
                    logger.error(f"‚ùå SlackÈÄöÁü•Âá¶ÁêÜ‰∏≠„Å´„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü: {e}")
                    logger.error(traceback.format_exc())
            elif slack_enabled:
                logger.warning("AlertManager„ÅåÂàùÊúüÂåñ„Åï„Çå„Å¶„ÅÑ„Å™„ÅÑ„Åü„ÇÅ„ÄÅSlackÈÄöÁü•„ÇíÈÄÅ‰ø°„Åß„Åç„Åæ„Åõ„Çì")
            else:
                logger.info("SlackÈÄöÁü•„ÅØÁÑ°ÂäπÂåñ„Åï„Çå„Å¶„ÅÑ„Åæ„Åô")
            
            return {
                'statusCode': 200,
                'body': json.dumps({
                    'success': True,
                    'execution_time': f"{execution_time:.2f} seconds",
                    'results': results,
                    'success_count': success_count,
                    'failure_count': failure_count
                })
            }
        except ImportError as e:
            logger.error(f"‰æùÂ≠òÈñ¢‰øÇ„ÅÆ„Ç§„É≥„Éù„Éº„Éà„Å´Â§±Êïó„Åó„Åæ„Åó„Åü: {e}")
            logger.error(traceback.format_exc())
            raise
    except Exception as e:
        # „Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„ÅüÂ†¥Âêà
        end_time = time.time()
        execution_time = end_time - start_time
        
        logger.error(f"‚ùå LambdaÈñ¢Êï∞„Åß„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü: {e}")
        logger.error(traceback.format_exc())
        
        # „Ç®„É©„ÉºÈÄöÁü•„ÇíSlack„Å´ÈÄÅ‰ø°
        if slack_enabled and alert_manager:
            try:
                # ÂÆüË°åÁí∞Â¢ÉÊÉÖÂ†±„ÇíÂèñÂæó
                env_info = f"Environment: {env_type}"
                utc_timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                jst_timestamp = get_jst_time().strftime("%Y-%m-%d %H:%M:%S")
                
                # „Ç®„É©„ÉºÊÉÖÂ†±„ÇíË©≥Á¥∞„Å´Âê´„ÇÅ„Çã
                error_fields = [
                    {"title": "Environment", "value": env_type, "short": True},
                    {"title": "Execution Time", "value": f"{execution_time:.2f} seconds", "short": True},
                    {"title": "Timestamp (UTC)", "value": utc_timestamp, "short": True},
                    {"title": "Timestamp (JST)", "value": jst_timestamp, "short": True},
                    {"title": "Error", "value": str(e), "short": False}
                ]
                
                # „Ç®„É©„Éº„Ç¢„É©„Éº„Éà„ÇíÈÄÅ‰ø°
                alert_message = f"‚ùå Lambda: Daily stock data fetch failed with error"
                alert_details = f"""
ERROR: Lambda function execution failed.

Execution time: {execution_time:.2f} seconds
Environment: {env_type}
Error: {str(e)}

Stack trace:
{traceback.format_exc()}
"""
                alert_manager.send_error_alert(
                    alert_message,
                    alert_details,
                    source="lambda_function.py",
                    send_email=False,
                    send_slack=True,
                    additional_fields=error_fields
                )
                logger.info("‚úÖ „Ç®„É©„ÉºÈÄöÁü•„ÇíÈÄÅ‰ø°„Åó„Åæ„Åó„Åü")
            except Exception as notify_error:
                logger.error(f"‚ùå SlackÈÄöÁü•Âá¶ÁêÜ‰∏≠„Å´„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü: {notify_error}")
                logger.error(traceback.format_exc())
        
        # LambdaÈñ¢Êï∞„ÅÆÊàª„ÇäÂÄ§Ôºà„Ç®„É©„ÉºÔºâ
        return {
            'statusCode': 500,
            'body': json.dumps({
                'success': False,
                'execution_time': f"{execution_time:.2f} seconds",
                'error': str(e)
            })
        }

# „É≠„Éº„Ç´„É´„ÉÜ„Çπ„ÉàÁî®
if __name__ == "__main__":
    try:
        # „ÉÜ„Çπ„ÉàÁî®„ÅÆ„Ç§„Éô„É≥„Éà„Å®„Ç≥„É≥„ÉÜ„Ç≠„Çπ„Éà
        test_event = {}
        test_context = None
        
        # LambdaÈñ¢Êï∞„ÇíÂÆüË°å
        result = lambda_handler(test_event, test_context)
        print(f"Lambda function result: {json.dumps(result, indent=2)}")
    except Exception as e:
        # Catch any unexpected exceptions
        print(f"‚ùå Critical error: {e}")
        traceback.print_exc()
        sys.exit(1)
