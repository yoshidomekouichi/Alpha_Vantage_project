#!/usr/bin/env python3
"""
AWS Lambda Function for Daily Stock Data Fetching (Mock Test Version)

This Lambda function simulates fetching the latest daily stock data from Alpha Vantage API
and storing it in AWS S3 or PostgreSQL. It is designed to be used for testing with mock mode enabled.
"""

import os
import sys
import json
import logging
import time
import traceback
from datetime import datetime, timedelta

# ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³å‡¦ç†ç”¨
try:
    # Python 3.9ä»¥é™ã®æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
    from zoneinfo import ZoneInfo
    def get_jst_time():
        return datetime.now(ZoneInfo("Asia/Tokyo"))
except ImportError:
    # Python 3.9æœªæº€ã¾ãŸã¯zoneinfoéå¯¾å¿œç’°å¢ƒç”¨
    try:
        import pytz
        def get_jst_time():
            return datetime.now(pytz.timezone('Asia/Tokyo'))
    except ImportError:
        # pytzã‚‚åˆ©ç”¨ã§ããªã„å ´åˆã¯ã€UTCã«9æ™‚é–“ã‚’åŠ ç®—
        def get_jst_time():
            return datetime.now() + timedelta(hours=9)

# PostgreSQLæ¥ç¶šç”¨
try:
    import psycopg2
    import psycopg2.extras
    POSTGRES_AVAILABLE = True
except ImportError:
    POSTGRES_AVAILABLE = False
    print("psycopg2ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„ãŸã‚ã€PostgreSQLã¯ä½¿ç”¨ã§ãã¾ã›ã‚“ã€‚")

# ãƒ­ã‚¬ãƒ¼åˆæœŸåŒ–
logger = logging.getLogger()
logger.setLevel(logging.INFO)

def setup_logging():
    """
    Set up logging configuration.
    
    Returns:
        Logger object
    """
    # ãƒ­ã‚¬ãƒ¼åˆæœŸåŒ–
    logger = logging.getLogger(__name__)
    
    # Lambdaç’°å¢ƒã§ã¯ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’/tmpä»¥ä¸‹ã«è¨­å®š
    log_dir = '/tmp/logs'
    
    # ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
    try:
        os.makedirs(log_dir, exist_ok=True)
        logger.info(f"ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã—ã¾ã—ãŸ: {log_dir}")
    except Exception as e:
        logger.error(f"ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        logger.error(traceback.format_exc())
    
    # ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’è¨­å®š
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    
    # ãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ãƒ¼ã‚’è¨­å®š
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    console_handler.setFormatter(formatter)
    
    # ãƒ­ã‚¬ãƒ¼ã«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’è¿½åŠ 
    logger.addHandler(console_handler)
    
    return logger

def get_postgres_connection():
    """
    PostgreSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã®æ¥ç¶šã‚’å–å¾—ã™ã‚‹
    
    Returns:
        Connection: PostgreSQLæ¥ç¶šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    """
    if not POSTGRES_AVAILABLE:
        raise ImportError("psycopg2ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„ãŸã‚ã€PostgreSQLã¯ä½¿ç”¨ã§ãã¾ã›ã‚“ã€‚")
    
    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰æ¥ç¶šæƒ…å ±ã‚’å–å¾—
    db_name = os.environ.get('POSTGRES_DB', 'prod_db')
    user = os.environ.get('POSTGRES_USER', 'myuser')
    password = os.environ.get('POSTGRES_PASSWORD', '0000')
    host = os.environ.get('POSTGRES_HOST', 'localhost')
    port = os.environ.get('POSTGRES_PORT', '5434')
    
    # æ¥ç¶šæ–‡å­—åˆ—ã‚’ä½œæˆ
    conn_string = f"dbname='{db_name}' user='{user}' password='{password}' host='{host}' port='{port}'"
    
    # æ¥ç¶šã‚’ä½œæˆ
    conn = psycopg2.connect(conn_string)
    
    return conn

def create_tables_if_not_exist(conn):
    """
    å¿…è¦ãªãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆã™ã‚‹
    
    Args:
        conn: PostgreSQLæ¥ç¶šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    """
    with conn.cursor() as cur:
        # stock_dataãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆ
        cur.execute("""
        CREATE TABLE IF NOT EXISTS stock_data (
            id SERIAL PRIMARY KEY,
            symbol VARCHAR(10) NOT NULL,
            date DATE NOT NULL,
            timestamp TIMESTAMP NOT NULL,
            open NUMERIC(10, 2) NOT NULL,
            high NUMERIC(10, 2) NOT NULL,
            low NUMERIC(10, 2) NOT NULL,
            close NUMERIC(10, 2) NOT NULL,
            volume BIGINT NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(symbol, date)
        );
        """)
        
        # stock_metadataãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆ
        cur.execute("""
        CREATE TABLE IF NOT EXISTS stock_metadata (
            id SERIAL PRIMARY KEY,
            symbol VARCHAR(10) NOT NULL,
            last_updated TIMESTAMP NOT NULL,
            latest_date DATE NOT NULL,
            data_points INTEGER NOT NULL,
            start_date DATE NOT NULL,
            end_date DATE NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(symbol)
        );
        """)
        
        conn.commit()

def save_to_postgres(conn, stock_data, logger):
    """
    PostgreSQLã«ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã™ã‚‹
    
    Args:
        conn: PostgreSQLæ¥ç¶šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        stock_data: ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿
        logger: ãƒ­ã‚¬ãƒ¼ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    """
    try:
        with conn.cursor() as cur:
            # stock_dataãƒ†ãƒ¼ãƒ–ãƒ«ã«ãƒ‡ãƒ¼ã‚¿ã‚’æŒ¿å…¥ã¾ãŸã¯æ›´æ–°
            cur.execute("""
            INSERT INTO stock_data (symbol, date, timestamp, open, high, low, close, volume)
            VALUES (%(symbol)s, %(date)s, %(timestamp)s, %(open)s, %(high)s, %(low)s, %(close)s, %(volume)s)
            ON CONFLICT (symbol, date) 
            DO UPDATE SET 
                timestamp = EXCLUDED.timestamp,
                open = EXCLUDED.open,
                high = EXCLUDED.high,
                low = EXCLUDED.low,
                close = EXCLUDED.close,
                volume = EXCLUDED.volume;
            """, {
                'symbol': stock_data['symbol'],
                'date': stock_data['date'],
                'timestamp': stock_data['timestamp'],
                'open': stock_data['open'],
                'high': stock_data['high'],
                'low': stock_data['low'],
                'close': stock_data['close'],
                'volume': stock_data['volume']
            })
            
            # stock_metadataãƒ†ãƒ¼ãƒ–ãƒ«ã«ãƒ‡ãƒ¼ã‚¿ã‚’æŒ¿å…¥ã¾ãŸã¯æ›´æ–°
            cur.execute("""
            INSERT INTO stock_metadata (symbol, last_updated, latest_date, data_points, start_date, end_date)
            VALUES (%(symbol)s, %(last_updated)s, %(latest_date)s, %(data_points)s, %(start_date)s, %(end_date)s)
            ON CONFLICT (symbol) 
            DO UPDATE SET 
                last_updated = EXCLUDED.last_updated,
                latest_date = EXCLUDED.latest_date,
                data_points = EXCLUDED.data_points,
                start_date = EXCLUDED.start_date,
                end_date = EXCLUDED.end_date;
            """, {
                'symbol': stock_data['symbol'],
                'last_updated': datetime.now().isoformat(),
                'latest_date': stock_data['date'],
                'data_points': 1,
                'start_date': stock_data['date'],
                'end_date': stock_data['date']
            })
            
            conn.commit()
            logger.info(f"PostgreSQLã«ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {stock_data['symbol']} ({stock_data['date']})")
            
    except Exception as e:
        conn.rollback()
        logger.error(f"PostgreSQLã¸ã®ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        logger.error(traceback.format_exc())
        raise

def lambda_handler(event, context):
    """
    AWS Lambda handler function.
    
    Args:
        event: Lambda event data
        context: Lambda context
        
    Returns:
        Dictionary with execution results
    """
    start_time = time.time()
    
    # ãƒ­ã‚®ãƒ³ã‚°ã®è¨­å®š
    logger = setup_logging()
    
    # ç’°å¢ƒå¤‰æ•°ã‚’å–å¾—
    api_key = os.environ.get('ALPHA_VANTAGE_API_KEY', 'demo')
    s3_bucket = os.environ.get('S3_BUCKET', 'mock-bucket')
    region = os.environ.get('REGION', 'ap-northeast-1')
    stock_symbols = os.environ.get('STOCK_SYMBOLS', 'NVDA,AAPL,MSFT')
    mock_mode = os.environ.get('MOCK_MODE', 'true').lower() == 'true'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§mockãƒ¢ãƒ¼ãƒ‰
    debug_mode = os.environ.get('DEBUG_MODE', 'true').lower() == 'true'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§debugãƒ¢ãƒ¼ãƒ‰
    storage_type = os.environ.get('STORAGE_TYPE', 's3').lower()  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§S3
    
    # å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ã‚’è¨­å®š
    env_type = "Lambda (SAM Test)"
    if mock_mode:
        env_type += " (Mock)"
    
    # å®Ÿè¡Œé–‹å§‹ãƒ­ã‚°
    logger.info("=" * 80)
    logger.info(f"ğŸš€ Starting Lambda function for daily stock data fetch at {datetime.now().isoformat()}")
    logger.info(f"ğŸ”§ Environment: {env_type}")
    logger.info(f"ğŸ”‘ API Key: {'*' * (len(api_key) - 4) + api_key[-4:] if len(api_key) > 4 else '****'}")
    logger.info(f"ğŸª£ S3 Bucket: {s3_bucket}")
    logger.info(f"ğŸŒ Region: {region}")
    logger.info(f"ğŸ“Š Stock Symbols: {stock_symbols}")
    logger.info(f"ğŸ› Debug Mode: {debug_mode}")
    logger.info(f"ğŸ’¾ Storage Type: {storage_type}")
    logger.info("=" * 80)
    
    # PostgreSQLæ¥ç¶šã®åˆæœŸåŒ–ï¼ˆstorage_typeãŒpostgresã®å ´åˆï¼‰
    postgres_conn = None
    if storage_type == 'postgres':
        try:
            logger.info("PostgreSQLã«æ¥ç¶šã—ã¦ã„ã¾ã™...")
            postgres_conn = get_postgres_connection()
            create_tables_if_not_exist(postgres_conn)
            logger.info("PostgreSQLã«æ¥ç¶šã—ã¾ã—ãŸ")
        except Exception as e:
            logger.error(f"PostgreSQLã¸ã®æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            logger.error(traceback.format_exc())
            if storage_type == 'postgres':
                # PostgreSQLãŒå¿…é ˆã®å ´åˆã¯ã‚¨ãƒ©ãƒ¼ã‚’ç™ºç”Ÿã•ã›ã‚‹
                raise
    
    try:
        # ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
        if mock_mode:
            logger.info("ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œä¸­ã§ã™ã€‚ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã—ã¾ã™ã€‚")
            
            # æ ªå¼ã‚·ãƒ³ãƒœãƒ«ã®ãƒªã‚¹ãƒˆ
            symbols = stock_symbols.split(',')
            
            # å„ã‚·ãƒ³ãƒœãƒ«ã«å¯¾ã—ã¦ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
            results = {}
            for symbol in symbols:
                logger.info(f"ã‚·ãƒ³ãƒœãƒ« {symbol} ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã™...")
                
                # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
                dummy_data = {
                    'symbol': symbol,
                    'timestamp': datetime.now().isoformat(),
                    'date': datetime.now().strftime('%Y-%m-%d'),
                    'open': 100.0 + (hash(symbol) % 100),
                    'high': 110.0 + (hash(symbol) % 100),
                    'low': 90.0 + (hash(symbol) % 100),
                    'close': 105.0 + (hash(symbol) % 100),
                    'volume': 1000000 + (hash(symbol) % 1000000)
                }
                
                logger.info(f"ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {symbol}")
                logger.info(f"ãƒ‡ãƒ¼ã‚¿: {json.dumps(dummy_data, indent=2)}")
                
                # ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
                if storage_type == 'postgres' and postgres_conn:
                    try:
                        save_to_postgres(postgres_conn, dummy_data, logger)
                        results[symbol] = 'success'
                    except Exception as e:
                        logger.error(f"PostgreSQLã¸ã®ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                        results[symbol] = 'error'
                else:
                    # S3ã¸ã®ä¿å­˜ã¯ãƒ¢ãƒƒã‚¯ã¨ã—ã¦æˆåŠŸã‚’è¿”ã™
                    logger.info(f"S3ã«ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã™ï¼ˆãƒ¢ãƒƒã‚¯ï¼‰: s3://{s3_bucket}/{symbol}/latest.json")
                    results[symbol] = 'success'
                
            # å®Ÿè¡Œæ™‚é–“ã‚’è¨ˆç®—
            end_time = time.time()
            execution_time = end_time - start_time
            
            # çµæœã‚’é›†è¨ˆ
            success_count = sum(1 for result in results.values() if result == 'success')
            failure_count = sum(1 for result in results.values() if result != 'success')
            
            return {
                'statusCode': 200,
                'body': json.dumps({
                    'success': True,
                    'execution_time': f"{execution_time:.2f} seconds",
                    'message': 'Mock mode execution successful',
                    'storage_type': storage_type,
                    'results': results,
                    'success_count': success_count,
                    'failure_count': failure_count,
                    'data': {
                        'symbols': symbols,
                        'timestamp': datetime.now().isoformat()
                    }
                })
            }
        
        # å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿å–å¾—å‡¦ç†ï¼ˆãƒ¢ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã§ãªã„å ´åˆï¼‰
        logger.info("Alpha Vantage APIã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã™...")
        
        # ã“ã“ã§å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿å–å¾—å‡¦ç†ã‚’è¡Œã†ï¼ˆä»Šå›ã¯å®Ÿè£…ã—ãªã„ï¼‰
        logger.warning("ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ãŒç„¡åŠ¹ã§ã™ãŒã€å®Ÿéš›ã®APIå‘¼ã³å‡ºã—ã¯å®Ÿè£…ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        
        # å®Ÿè¡Œæ™‚é–“ã‚’è¨ˆç®—
        end_time = time.time()
        execution_time = end_time - start_time
        
        return {
            'statusCode': 200,
            'body': json.dumps({
                'success': False,
                'execution_time': f"{execution_time:.2f} seconds",
                'message': 'Non-mock mode not implemented',
            })
        }
    except Exception as e:
        # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆ
        end_time = time.time()
        execution_time = end_time - start_time
        
        logger.error(f"âŒ Lambdaé–¢æ•°ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        logger.error(traceback.format_exc())
        
        # Lambdaé–¢æ•°ã®æˆ»ã‚Šå€¤ï¼ˆã‚¨ãƒ©ãƒ¼ï¼‰
        return {
            'statusCode': 500,
            'body': json.dumps({
                'success': False,
                'execution_time': f"{execution_time:.2f} seconds",
                'error': str(e)
            })
        }
    finally:
        # PostgreSQLæ¥ç¶šã‚’é–‰ã˜ã‚‹
        if postgres_conn:
            postgres_conn.close()
            logger.info("PostgreSQLæ¥ç¶šã‚’é–‰ã˜ã¾ã—ãŸ")

# ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆç”¨
if __name__ == "__main__":
    try:
        # ãƒ†ã‚¹ãƒˆç”¨ã®ã‚¤ãƒ™ãƒ³ãƒˆã¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
        test_event = {}
        test_context = None
        
        # Lambdaé–¢æ•°ã‚’å®Ÿè¡Œ
        result = lambda_handler(test_event, test_context)
        print(f"Lambda function result: {json.dumps(result, indent=2)}")
    except Exception as e:
        # Catch any unexpected exceptions
        print(f"âŒ Critical error: {e}")
        traceback.print_exc()
        sys.exit(1)
